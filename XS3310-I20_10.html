<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
	"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">

<head>
<title>XS3310-I20_10.html</title>
<meta http-equiv="Content-Type" content="application/xhtml+xml;charset=utf-8"/>
<link rel="stylesheet" type="text/css" media="all" href="https://cdn.jsdelivr.net/npm/github-markdown-css/github-markdown.min.css"  />
<link rel="stylesheet" type="text/css" media="all" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/styles/github.min.css"  /><meta name='viewport' content='width=device-width, initial-scale=1, shrink-to-fit=no'><style> body { box-sizing: border-box; max-width: 740px; width: 100%; margin: 40px auto; padding: 0 10px; } </style><script id='MathJax-script' async src='https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'></script><script src='https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/highlight.min.js'></script><script>document.addEventListener('DOMContentLoaded', () => { document.body.classList.add('markdown-body'); document.querySelectorAll('pre[lang] > code').forEach((code) => { code.classList.add(code.parentElement.lang); }); document.querySelectorAll('pre > code').forEach((code) => { hljs.highlightBlock(code); }); });</script>
</head>

<body>

<p><code>{r setup, include=FALSE} knitr::opts_chunk$set(echo = TRUE)</code></p>
<p>class: center, middle</p>
<h1 id="qué-hemos-visto-hasta-ahora">¿Qué hemos visto hasta ahora?</h1>
<p>Todo sobre estimadores puntuales + intro a los pivotes. Algunos intervalos de confianza clásicos.</p>
<h1 id="qué-vamos-a-discutir-hoy">¿Qué vamos a discutir hoy?</h1>
<p>Otros intervalos de confianza clásicos. Intervalos de confianza para muestras grandes. Funciones estabilizadores de varianza.</p>
<hr />
<h1 id="técnica-del-pivote">Técnica del pivote</h1>
<p><strong>La semana pasada:</strong></p>
<p>Esta técnica consiste en definir una variable aleatoria, <span class="math inline">\(U\)</span>, que llamaremos <strong>pivote</strong>. El pivote debe cumplir con las siguientes condiciones:</p>
<ul>
<li><p>Para una muestra aleatoria <span class="math inline">\(X_{1}, X_{2}, ... , X_{n}\)</span> y un parámetro desconocido <span class="math inline">\(\theta\)</span>, <span class="math inline">\(U\)</span> debe estar definido en términos de los elementos de la muestra aleatoria y del parámetro desconocido, donde el parámetro desconocido <span class="math inline">\(\theta\)</span> sea la única cantidad desconocida.</p></li>
<li><p>La distribución de probabilidad de U debe ser conocido y no depender de <span class="math inline">\(\theta\)</span>.</p></li>
<li><p>Se recomienda iniciar con un estadístico suficiente</p></li>
<li><p>Se puede usar como guía las distribuciones con parámetros de posición - escala.</p></li>
</ul>
<hr />
<h1 id="ejemplo-de-un-intervalo-de-confianza-para-la-varianza-desconocida.">Ejemplo de un intervalo de confianza para la varianza desconocida.</h1>
<p>Se toma el tiempo en milisegundos para que los nervios se recuperen después de administrar una droga a 4 ratones.</p>
<p><span class="math display">\[1.7, 1.6, 1.8, 1.9\]</span></p>
<p>Calcule un intervalo de confianza para el promedio este tiempo a un 90% de confianza.</p>
<hr />
<p><em>Solución:</em></p>
<p>Para este caso tenemos que <span class="math inline">\(\bar{X} = 1.75\)</span> y <span class="math inline">\(S^{2} = 0.017\)</span> y <span class="math inline">\(S = \sqrt{0.017} = 0.13\)</span>.</p>
<p>En este caso vamos a tomar una <span class="math inline">\(t_{3,0.05} = 2.353\)</span> (<span class="math inline">\(\alpha/2 = 0.1/2 = 0.05\)</span>)</p>
<p><span class="math display">\[\begin{align*}
&amp; P\left(\bar{X}- t_{3,0.05} \frac{s}{\sqrt{4}} \leq \mu \leq \bar{X}+ t_{3,0.05} \frac{s}{\sqrt{n}}\right) \\
&amp; = P\left(1.75- 2.353 \frac{0.13}{2}  \leq \mu \leq 1.75+ 2.353 \frac{0.13}{2} \right) \\
&amp;= P\left(1.597  \leq \mu \leq 1.903 \right) = 0.9.
\end{align*}\]</span></p>
<hr />
<h2 id="ejemplos-de-un-intervalo-de-confianza-para-la-diferencia-de-medias">Ejemplos de un intervalo de confianza para la diferencia de medias</h2>
<p>En un hospital se realiza un estudio sobre la influencia del estrés en el peso de los bebés al nacer. Se consideran dos grupos de mujeres embarazadas: aquellas que viven en el campo y aquellas que viven en la ciudad, y se obtienen los siguientes datos sobre el peso de sus hijos.</p>
<p><span class="math display">\[\begin{equation*}
\begin{array}{|c|c||c|c|}
\hline &amp; \text { Muestra } &amp; \begin{array}{c}
\text { Peso medio } \\
\text { de los bebés }
\end{array} &amp; \begin{array}{c}
\text { Desviación } \\
\text { estándar }
\end{array} \\
\hline \text { campo } &amp; \mathrm{n}_{1}=320 &amp; \overline{\mathrm{X}}_{1}=3,8 &amp; \sigma_{1}=0,6 \\
\hline \text { ciudad } &amp; \mathrm{n}_{2}=240 &amp; \overline{\mathrm{X}}_{2}=3,4 &amp; \sigma_{2}=0,8 \\
\hline
\end{array}
\end{equation*}\]</span></p>
<p>Asumiendo que los datos normales, determine cómo influye que la madre viva en el campo o en la ciudad en el peso de su hijo al nacer, utilizando un intervalo de confianza para la diferencia de medias con un nivel de confianza del 95%.</p>
<hr />
<p><strong>Solución:</strong> Intervalo de confianza del <span class="math inline">\(95 \%\)</span>:</p>
<p><span class="math inline">\(1-\alpha=0.95 \Rightarrow \alpha=1-0,95=0,05\)</span></p>
<p>Buscamos en el la tabla de normales aquel valor que cumpla <span class="math inline">\(P(Z\leq z_{\alpha / 2}) = 0.05/2 = 0.025\)</span></p>
<p>Obtenemos que <span class="math inline">\(\Rightarrow z_{\alpha / 2}=z_{0,025}=1,96\)</span></p>
<p><span class="math display">\[\begin{align*}
&amp;\left(\left(\overline{\mathrm{X}}_{1}-\overline{\mathrm{X}}_{2}\right)-z_{\alpha / 2} \sqrt{\frac{\sigma_{1}^{2}}{\mathrm{n}_{1}}+\frac{\sigma_{2}^{2}}{\mathrm{n}_{2}}},\left(\overline{\mathrm{X}}_{1}-\overline{\mathrm{X}}_{2}\right)+z_{\alpha / 2} \sqrt{\frac{\sigma_{1}^{2}}{\mathrm{n}_{1}}+\frac{\sigma_{2}^{2}}{\mathrm{n}_{2}}}\right) \\
&amp;=\left((3,8-3,4)-1,96 \sqrt{\frac{0,6^{2}}{320}+\frac{0,8^{2}}{240}},(3,8-3,4)+1,96 \sqrt{\frac{0,6^{2}}{320}+\frac{0,8^{2}}{240}}\right)\\
&amp;=[0,279,0,520]
\end{align*}\]</span></p>
<hr />
<h2 id="intervalos-de-confianza-para-poblaciones-normales">Intervalos de confianza para poblaciones normales</h2>
<h3 id="intervalo-de-confianza-para-sigma2">Intervalo de confianza para <span class="math inline">\(\sigma^2\)</span></h3>
<p>Nos interesa constuir un intervalo de confianza de probabilidad <span class="math inline">\(1-\alpha\)</span> para la variancia poblacional, <span class="math inline">\(\sigma^2\)</span>. En este caso nuestra población sigue siendo Normal con parámetros <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma^2\)</span>, donde ambos parámetros son desconocidos. Si queremos obtener una estimación por intervalo para <span class="math inline">\(\sigma^2\)</span> debemos primero obtener una variable aleatoria que funcione como pivote. En este caso esta variable aleatoria debe estar en términos de <span class="math inline">\(X_{1}, X_{2}, ... , X_{n}\)</span> y de <span class="math inline">\(\sigma^2\)</span>, y su distribución no puede depender de <span class="math inline">\(\sigma^2\)</span>. Con lo que conocemos de transformaciones a partir de muestras Normales podríamos utilizar el siguiente pivote:</p>
<p><span class="math display">\[U = \frac{(n-1)S^{2}}{\sigma^2}\]</span></p>
<hr />
<h2 id="intervalo-de-confianza-para-sigma2-1">Intervalo de confianza para <span class="math inline">\(\sigma^2\)</span></h2>
<p>Sabemos que <span class="math inline">\(U \sim \chi^{2}(n-1)\)</span>. Por lo tanto esta variable aleatoria cumple todas las condiciones necesarias para ser un pivote. Ahora debemos encontrar los valores de <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span> tales que:</p>
<p><span class="math display">\[P(U &lt; a) = \frac{\alpha}{2} \qquad P(U &gt; b) = \frac{\alpha}{2}\]</span></p>
<p>El valor de <span class="math inline">\(a\)</span> es aquel que acumula <span class="math inline">\(1-\frac{\alpha}{2}\)</span> a su derecha, mientras que el valor de <span class="math inline">\(b\)</span> solo acumula <span class="math inline">\(\frac{\alpha}{2}\)</span> a la derecha. Por lo tanto tenemos que <span class="math inline">\(a = \chi^{2}_{1-\frac{\alpha}{2}, n-1}\)</span> y <span class="math inline">\(b = \chi^{2}_{\frac{\alpha}{2}, n-1}\)</span>. En este caso no hay simetría que podamos utilizar para poner <span class="math inline">\(a\)</span> en términos de <span class="math inline">\(b\)</span> como hemos estado haciendo anteriormente. Ahora despejamos <span class="math inline">\(\sigma^2\)</span>:</p>
<p><span class="math display">\[\begin{align*}
P(a \leq U \leq b) &amp;= P\left( \chi^{2}_{1-\frac{\alpha}{2}, n-1}  \leq  \frac{(n-1)S^{2}}{\sigma^2} \leq \chi^{2}_{\frac{\alpha}{2}, n-1} \right) \\
&amp;= P\left( \frac{(n-1)S^{2}}{\chi^{2}_{\frac{\alpha}{2}, n-1}}  \leq \sigma^2 \leq  \frac{(n-1)S^{2}}{\chi^{2}_{1-\frac{\alpha}{2}, n-1}}  \right) = 1 - \alpha
\end{align*}\]</span></p>
<hr />
<h2 id="intervalo-de-confianza-para-sigma2-2">Intervalo de confianza para <span class="math inline">\(\sigma^2\)</span></h2>
<p>Por lo tanto, con una confianza del <span class="math inline">\((1 - \alpha)\%\)</span> el intervalo <span class="math inline">\(\left[ \frac{(n-1)S^{2}}{\chi^{2}_{\frac{\alpha}{2}, n-1}} , \frac{(n-1)S^{2}}{\chi^{2}_{1-\frac{\alpha}{2}, n-1}} \right]\)</span> incluye el valor de <span class="math inline">\(\sigma^2\)</span>.</p>
<p>Ahora volvemos al caso donde tenemos dos poblaciones independientes, una de las cuales es <span class="math inline">\(N(\mu_{1}, \sigma^{2}_{1})\)</span> y la otra es <span class="math inline">\(N(\mu_{2}, \sigma^{2}_{2})\)</span>. Supongase que se obtiene una muestra <span class="math inline">\(X_{1}, X_{2}, ... , X_{n}\)</span> de la primera población y otra <span class="math inline">\(Y_{1}, Y_{2}, ... , Y_{m}\)</span> de la segunda. Nuestro interés yace en encontrar una estimación por intervalo, con probabilidad <span class="math inline">\(1-\alpha\)</span>, para el parámetro <span class="math inline">\(\frac{\sigma^2_{1}}{\sigma^2_{2}}\)</span>.</p>
<hr />
<h2 id="intervalo-de-confianza-para-fracsigma2_1sigma2_2">Intervalo de confianza para <span class="math inline">\(\frac{\sigma^2_{1}}{\sigma^2_{2}}\)</span></h2>
<p>Debemos construir un parámetro que incluya las dos muestras aleatorias y al parámetros desconocido. En el caso anterior habiamos usado una <span class="math inline">\(\chi^{2}\)</span>-cuadrado como pivote ya que esta incluía la muestra aleatoria y la varianza poblacional. Podriamos pensar en hacer lo mismo para cada muestra y de alguna forma juntar ambas <span class="math inline">\(\chi^{2}\)</span>-cuadrado. Para ello recordemos la forma de una distribución F: <span class="math display">\[F =\frac{\frac{V}{v_1}}{\frac{W}{v_2}}\]</span></p>
<p>donde <span class="math inline">\(V \sim \chi^{2}(v_1)\)</span> y <span class="math inline">\(W \sim \chi^{2}(v_2)\)</span>. Sabemos de antemano que <span class="math inline">\(\frac{(n - 1)S^{2}_{1}}{\sigma^{2}_{1}} ~ \chi^{2}(n-1)\)</span> y <span class="math inline">\(\frac{(m - 1)S^{2}_{2}}{\sigma^{2}_{2}} ~ \chi^{2}(m-1)\)</span>. Podemos usar estas variables aleatorias en la construcción de una F que incluya el parámetro de interés:</p>
<p><span class="math display">\[F = \frac{\frac{\frac{(n - 1)S^{2}_{1}}{\sigma^{2}_{1}}}{n-1}}{\frac{\frac{(m - 1)S^{2}_{2}}{\sigma^{2}_{2}}}{m-1}} = \frac{S^{2}_{1}}{S^{2}_{2}} \cdot \frac{\sigma^{2}_{2}}{\sigma^{2}_{1}} \sim F(n-1,m-1)\]</span></p>
<hr />
<h2 id="intervalo-de-confianza-para-fracsigma2_1sigma2_2-1">Intervalo de confianza para <span class="math inline">\(\frac{\sigma^2_{1}}{\sigma^2_{2}}\)</span></h2>
<p>Esta variable aleatoria cumple todas las condiciones para ser un pivote y podemos usarlo para encontrar los valores de <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span>. Recordemos que se debe cumplir que <span class="math inline">\(P(F&lt;a) = P(F&gt;b) = \frac{\alpha}{2}\)</span>. Podemos hacer uso de las tablas de la F, la cual acumula hacia la derecha. Por lo tanto tenemos que <span class="math inline">\(a\)</span> es el valor F que acumula <span class="math inline">\(1-\frac{\alpha}{2}\)</span> a la derecha mientras que <span class="math inline">\(b\)</span> acumula <span class="math inline">\(\frac{\alpha}{2}\)</span>. Podemos notar estos valores como</p>
<p><span class="math inline">\(a = F_{1-\frac{\alpha}{2}, n-1, m-1} \qquad b = F_{\frac{\alpha}{2}, n-1, m-1}\)</span></p>
<p>No obstante, vemos que hay un problema al usar las tablas para encontrar <span class="math inline">\(F_{1-\frac{\alpha}{2}, n-1, m-1}\)</span> si la probabilidad que se busca es mayor a 0.20, el cual es el caso en la gran mayoría de los casos. Para ello podemos hacer uso de una propiedad de la distribución F, que dice que la inversa multiplicativa de una F también se distribuye F pero con los grados de libertad del numerador y denominador intercambiados. Por lo tanto podemos decir que: <span class="math inline">\(a = F_{1-\frac{\alpha}{2}, n-1, m-1} = F^{-1}_{\frac{\alpha}{2}, m-1, n-1}\)</span>.</p>
<hr />
<h2 id="intervalo-de-confianza-para-fracsigma2_1sigma2_2-2">Intervalo de confianza para <span class="math inline">\(\frac{\sigma^2_{1}}{\sigma^2_{2}}\)</span></h2>
<p>Finalmente podemos proceder a despejar el valor del parámetro de interés de la expresión <span class="math inline">\(P(a \leq F \leq b)\)</span> y obtenemos el siguiente intervalo:</p>
<p><span class="math display">\[\left[ \frac{\frac{S^{2}_{1}}{S^{2}_{2}}}{F_{\frac{\alpha}{2}, n-1, m-1}} , \frac{\frac{S^{2}_{1}}{S^{2}_{2}}}{F^{-1}_{\frac{\alpha}{2}, m-1, n-1}} \right]\]</span></p>
<p>el cual incluye el valor de <span class="math inline">\(\frac{\sigma^{2}_{1}}{\sigma^{2}_{2}}\)</span> con una confianza del <span class="math inline">\((1-\alpha)\%\)</span>.</p>
<hr />
<p><strong>Ejercicio:</strong> Un instituto de investigaciones agronómicas siembra, en cinco parcelas diferentes, dos tipos de maíz híbrido. Las producciones en quintales métricos por hectárea son:</p>
<p><span class="math display">\[\begin{equation*}
\begin{array}{|l|c|c|c|c|c|}
\cline { 2 - 6 } \multicolumn{1}{c|} {} &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 \\
\hline \text { Híbrido I } &amp; 90 &amp; 85 &amp; 95 &amp; 76 &amp; 80 \\
\hline \text { Híbrido II } &amp; 84 &amp; 87 &amp; 90 &amp; 92 &amp; 90 \\
\hline
\end{array}
\end{equation*}\]</span></p>
<p>Construir un intervalo de confianza para el cociente de varianzas con un error de significación de 0,10 .</p>
<hr />
<p><strong>Solución:</strong> Asumiendo que las poblaciones son normales defina <span class="math inline">\(\mathrm{X}_{1}\equiv\)</span> ‘Producción de maíz del híbrido I’ como <span class="math inline">\(\mathrm{N}\left(\mu_{1},\sigma_{1}\right)\)</span> y <span class="math inline">\(\mathrm{X}_{2} \equiv\)</span> ’ Producción de maíz del híbrido II’ sigue una distribución <span class="math inline">\(\mathrm{N}\left(\mu_{2}, \sigma_{2}\right)\)</span></p>
<p>Entonces</p>
<p><span class="math display">\[\begin{equation*}
\begin{array}{llll}
n_{1}=5 &amp; \bar{x}_{1}=85,20 &amp; s_{1}^{2}=57,7 &amp; \alpha / 2=0,05 \\
n_{2}=5 &amp; \bar{x}_{2}=88,6 &amp; s_{2}^{2}=9,8 &amp; s_{1}^{2} / s_{2}^{2}=57,7 / 9,8=5,89 \\
\end{array}
\end{equation*}\]</span></p>
<p><span class="math display">\[F_{0,05 ; 4,4}  =6,3883 \quad  F_{0,95 ; 4,4}=1 / F_{0,05 ; 4,4}=1 / 6,3883=0,1565\]</span></p>
<p><span class="math display">\[\begin{align*}
&amp; \left[ \frac{\frac{S^{2}_{1}}{S^{2}_{2}}}{F_{0.05, 5-1, 5-1}} , \frac{\frac{S^{2}_{1}}{S^{2}_{2}}}{F^{-1}_{0.05, 5-1, 5-1}} \right] \\
&amp; = \left[ \frac{5.89}{6.3883} , \frac{5.89}{0.1565} \right] \\
&amp; = \left[ 0.92, 37.64 \right]
\end{align*}\]</span></p>
<hr />
<h1 id="intervalos-de-confianza-para-muestras-grandes">Intervalos de confianza para muestras grandes</h1>
<p>Recordemos que cuando <span class="math inline">\(n \to +\infty\)</span> el Teorema del Límite Central nos dice que <span class="math inline">\(\overline{X}\)</span> converge en distribución a una <span class="math inline">\(N(\mu, \frac{\sigma^2}{n})\)</span>. Por lo tanto, si queremos hacer una estimación por intervalo para <span class="math inline">\(\mu\)</span>, suponiendo que conocemos el valor de <span class="math inline">\(\sigma^2\)</span>, podemos hacer uso del siguiente pivote:</p>
<p><span class="math display">\[Z_{n} = \frac{\overline{X}-\mu}{\frac{\sigma}{\sqrt{n}}}\]</span></p>
<p>De esta forma tenemos una cantidad pivote asintótica que se puede aplicar para este tipo de estimadores con muestras grandes. El desarrollo para obtener el intervalo es el mismo del caso de una estimación por intervalo para la media de una población normal. Por lo tanto tendremos un intervalo bilateral con probabilidad <span class="math inline">\(1-\alpha\)</span>:</p>
<p><span class="math display">\[\overline{X} \pm z_{1-\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}}\]</span></p>
<hr />
<h2 id="intervalos-de-confianza-para-muestras-grandes-método-de-wald">Intervalos de confianza para muestras grandes (Método de Wald)</h2>
<p>Existen varios estimadores que se puede comprobar que tienen la forma de un <span class="math inline">\(\overline{X}\)</span> como por ejemplo <span class="math inline">\(\hat{p}\)</span>, <span class="math inline">\(\overline{X} - \overline{Y}\)</span> y <span class="math inline">\(\hat{p}_{1} - \hat{p}_{2}\)</span>, para estimar <span class="math inline">\(p\)</span>, <span class="math inline">\(\mu_{1} - \mu_{2}\)</span> y <span class="math inline">\(p_{1} - p_{2}\)</span> respectivamente. Cada uno de estos caso también tendrá una expresión específica para la variancia <span class="math inline">\((\frac{p(1-p)}{n}\)</span>, <span class="math inline">\(\frac{\sigma^{2}_{1}}{n_{1}} + \frac{\sigma^{2}_{2}}{n_{2}}\)</span> y <span class="math inline">\(\frac{p_{1}(1-p_{1})}{n_{1}} + \frac{p_{2}(1-p_{2})}{n_{2}}\)</span>, respectivamente).</p>
<p>Nótese que este intervalo supone que conocemos la varancia poblacional de nuestra población. Sin embargo, podemos hacer uso del Teorema de Slutsky para mantener el pivote que converge en distribución a una <span class="math inline">\(N(0,1)\)</span> si conocemos un estimador consistente para la variancia poblacional. Este reemplazaría la variancia poblacional por su estimador consistente en la fórmula del intervalo anterior.</p>
<hr />
<p><strong>Ejemplo:</strong> Se registraron los tiempos de compra de <span class="math inline">\(n=64\)</span> clientes seleccionados al azar en un supermercado local. El promedio y varianza de los 64 tiempos de compra fueron 33 minutos y 256 minutos <span class="math inline">\(^{2}\)</span>, respectivamente. Estime <span class="math inline">\(\mu\)</span>, el verdadero promedio de tiempo de compra por cliente, con un coeficiente de confianza de <span class="math inline">\(1-\alpha=.90\)</span> usando el método de Wald.</p>
<p><strong>Solución:</strong> El intervalo tiene la forma <span class="math display">\[\begin{equation}
\bar{x} \pm z_{\alpha / 2}\left(\frac{\sigma}{\sqrt{n}}\right) \approx \bar{x} \pm z_{\alpha / 2}\left(\frac{s}{\sqrt{n}}\right)
\end{equation}\]</span></p>
<p>De la tabla de normales se deduce que <span class="math inline">\(z_{\alpha/2} = z_{0.05} = 1.645\)</span>.</p>
<p>Por lo tanto el intervalo es</p>
<p><span class="math display">\[\begin{align*}
&amp; \left[ 33-1.645\left(\frac{16}{8}\right), 33+1.645\left(\frac{16}{8}\right)    \right]
&amp;= \left[29.71, 36.29\right]
\end{align*}\]</span></p>
<hr />
<p><strong>Ejemplo</strong> Suponga que tienen datos te tiempos de espera en minutos en un banco con <span class="math inline">\(n=25\)</span> clientes. La distribución del tiempo se observa que sigue una distribución <span class="math inline">\(Poisson(\theta)\)</span> con <span class="math inline">\(\bar{X} = 5\)</span>. Cual es el intervalo de confianza para <span class="math inline">\(\theta\)</span> a un 95%.</p>
<p><strong>Solución:</strong> Recuerde que si <span class="math inline">\(X\)</span> es <span class="math inline">\(Poisson(\theta)\)</span>, entonces <span class="math inline">\(E[X] = Var(X) = \theta\)</span>.</p>
<p>Por el TLC se tiene que</p>
<p><span class="math display">\[\begin{equation}
\bar{X} \pm z_{\alpha / 2}\left(\frac{\sigma}{\sqrt{n}}\right) \approx \bar{X} \pm z_{\alpha / 2}\left(\frac{\sqrt{\theta}}{\sqrt{n}}\right) \approx  \bar{X} \pm z_{\alpha / 2}\left(\frac{\sqrt{\bar{X}}}{\sqrt{n}}\right)
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{align*}
&amp; \left[5-1.96\left(\frac{\sqrt{5}}{5}\right), 5-1.96\left(\frac{\sqrt{5}}{5}\right)    \right]   \\
&amp;= [4.12, 5.88] 
\end{align*}\]</span></p>
<hr />
<h1 id="funciones-estabilizadoras-de-varianza">Funciones estabilizadoras de varianza</h1>
<p>El caso anterior requería hacer el supuesto que los datos eran normales para construir el intervalo.</p>
<p>Vamos a ver si podemos hacerlo mejor.</p>
<p>La pregunta que siempre debemos hacernos, es</p>
<p>¿Cómo transformar <span class="math inline">\(\hat{\theta}\)</span> para que tenga varianza constante?</p>
<hr />
<p><strong>Ejemplo:</strong> Retomemos el caso de los clientes en el banco.</p>
<p>En este caso hicimos el supuesto de normalidad y aproximamos la varianza con <span class="math inline">\(\overline{X}\)</span></p>
<p>Por el método Delta, se tiene que para <span class="math inline">\(g\left(\bar{X}_{n}\right)\)</span></p>
<p>[ (g( - g()))  N(0,( g^{}() )^2) ]</p>
<p><span class="math display">\[\begin{equation*}
\left(g^{\prime}(\mu) \sigma\right)^{2}=g^{\prime}(\mu)^{2} \sigma^{2}(\mu)
\end{equation*}\]</span> Si se desea que la varianza sea constante con respecto a <span class="math inline">\(\mu\)</span>, <span class="math display">\[\begin{equation*}
\begin{aligned}
g^{\prime}(u)^{2} \sigma^{2}(\mu) &amp;=1 \\
\Longrightarrow g^{\prime}(\mu) &amp;=\frac{1}{\sigma(\mu)} \quad(\sigma(\mu)&gt;0) \\
\Longrightarrow g(\mu) &amp;=\int_{a}^{\mu} \frac{d x}{\sigma(x)} d x
\end{aligned}
\end{equation*}\]</span> donde <span class="math inline">\(a\)</span> es una constante arbitraria que hace la integral finita (y fácil de calcular).</p>
<hr />
<p>Del ejemplo anterior, recuerde que <span class="math inline">\(\sigma^{2}=\theta=\mu\)</span>, entonces se podría tomar que <span class="math inline">\(\sigma(\mu)=\sqrt{\mu}\)</span> por lo tanto definimos <span class="math display">\[\begin{equation*}
g(\mu)=\int_{0}^{\mu} \frac{d x}{\sqrt{x}}=2 \sqrt{\mu}
\end{equation*}\]</span></p>
<p>Por el método Delta, sabemos que</p>
<p>[ ( 2 {X}_{n}^{} - 2 ^{} )  N(0,1) ]</p>
<p>O lo que es equivalente <span class="math display">\[\begin{equation*}
2 \bar{X}_{n}^{\frac{1}{2}} \stackrel{d}{\to}  N\left(2 \theta^{\frac{1}{2}}, \frac{1}{n}\right)
\end{equation*}\]</span></p>
<p>De esta manera un intervalo de confianza para la cantidad (2) con nivel 95% sería</p>
<p><span class="math display">\[ 2 \bar{X}_{n}^{\frac{1}{2}} \pm z_{\frac{\alpha}{2}} \frac{1}{\sqrt{n}}\]</span></p>
<p>Usando los valores que teníamos anteriormente tenemos que</p>
<p><span class="math display">\[\begin{align*}
&amp; \left[ 2\sqrt{5}  - 1.96 \frac{1}{\sqrt{25}},  2\sqrt{5}  - 1.96 \frac{1}{\sqrt{25}} \right] \\
&amp;= [4.27, 4.67] 
\end{align*}\]</span></p>
<hr />
<p>Sin embargo esa cantidad no nos sirve para el ejercicio. Requerimos un intervalo para ().</p>
<p>Para eso vamos tomar la función inversa de cada uno de los extremos <span class="math inline">\(y=2 x^{\frac{1}{2}} \Longrightarrow x=\frac{y^{2}}{4}\)</span>. Aplicando esta transformación al intervalo anterior, se obtiene <span class="math display">\[\begin{equation*}
\end{equation*}\]</span></p>
<p><span class="math display">\[\begin{align*}
&amp; \left[\frac{1}{4}\left(2 \bar{X}_{n}^{\frac{1}{2}}-\frac{1}{\sqrt{n}} z_{\frac{\alpha}{2}}\right)^{2}, \frac{1}{4}\left(2 \bar{X}_{n}^{\frac{1}{2}}+\frac{1}{\sqrt{n}} z_{\frac{\alpha}{2}}\right)^{2}\right] \\
&amp;= \left[\frac{1}{4}\left( 4.27 \right)^{2}, \frac{1}{4}\left( 4.67 \right)^{2} \right] \\
&amp;= [4.56, 5.46]
\end{align*}\]</span></p>
<hr />
<p><strong>Ejemplo:</strong> Suponga que (X_i Binomial(n,p)) encuentre un intervalo de confianza para (p) usando el método de Wald y el método delta al 95%, con (n=25) y ({X} =0.5).</p>
<p>El estimador para (p) es ({X}).</p>
<p><em>Método Wald:</em></p>
<p><span class="math display">\[\begin{equation*}
\bar{X} \pm z_{\alpha / 2}\left(\frac{\sigma}{\sqrt{n}}\right) \approx \bar{X} \pm z_{\alpha / 2}\left(\frac{\sqrt{p(1-p)}}{\sqrt{n}}\right) \approx  \bar{X} \pm z_{\alpha / 2}\left(\frac{\sqrt{\bar{X}(1-\bar{X})}}{\sqrt{n}}\right)
\end{equation*}\]</span></p>
<p>Haciendo el cálculo correspondiente el intervalo queda en [ [0.304, 0.696] ]</p>
<hr />
<p><em>Método delta:</em></p>
<p>Hay que encontrar la (g(p)) para estabilizar la varianza.</p>
<p><span class="math display">\[\begin{equation*}
g(p)=\int_{a}^{p} \frac{1}{\sqrt{x(1-x)}} d x 
=  2\int_{a}^{\sqrt{p}} \frac{1}{\sqrt{1-u^2}} d u 
= 2 \arcsin(\sqrt{p})
\end{equation*}\]</span></p>
<p>[ ( 2 ({}) - 2({}))  N(0,1) ]</p>
<p>[2 ({}) z_{/2} ]</p>
<p>usando los valores obtenemos</p>
<p>[ [1.179, 1.963] ]</p>
<hr />
<p>[ y = 2 () x = (  )^2<br />
]</p>
<p><span class="math display">\[\begin{align*}
&amp; \left[\sin \left( \frac{1.179}{2} \right)^2, \sin \left( \frac{1.963}{2} \right)^2\right] \\
&amp;= [0.309, 0.691]
\end{align*}\]</span></p>
<hr />
<p><strong>Ejercicio:</strong> Suponga que ((X_i,Y_{i})) provienen de una distribución normal con correlación ().</p>
<p>Suponga que usted estima la correlación muestral con la siguiente fórmula:</p>
<p><span class="math display">\[\begin{equation*}
r_{n}=\frac{\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)\left(Y_{i}-\bar{Y}\right)}{\left\{\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2} \sum\left(Y_{i}-\bar{Y}\right)^{2}\right\}^{1 / 2}}
\end{equation*}\]</span></p>
<p>Haciendo mucho cálculos, encontramos <span class="math inline">\(Var(r_{n}) = 1-\rho^2\)</span>. Por lo tanto,</p>
<p><span class="math display">\[\begin{equation*}
\sqrt{n}\left(r_{n}-\rho\right) \rightsquigarrow N\left(0,\left(1-\rho^{2}\right)^{2}\right)
\end{equation*}\]</span></p>
<p>Si suponemos que (r_n = 0.3) y (n = 25), encuentre un intervalo de confianza para () al 95% usando un método de Wald y el método Delta.</p>
<p><strong>Sugerencia: </strong></p>
<p>Use el hecho que <span class="math display">\[\begin{equation*}
\int \frac{1}{1-\rho^{2}} d \rho=\frac{1}{2} \log \frac{1+\rho}{1-\rho}=\operatorname{arctanh} \rho
\end{equation*}\]</span></p>
<!-- # Bootstrap -->
<!-- * La inferencia frecuentista se basa en modelos y supuestos. En muchos casos, las expresiones acerca de la exactitud (tales como el error estándar) están basadas en teoría asintótica, y por lo tanto no deberían usarse con muestras pequeñas. -->
<!-- * En otros casos, no estamos usando teoría asintótica, pero no sabemos cómo hacer una suposición acerca de la distribución poblacional, debido a que la muestra no se parece a ninguna forma conocida. -->
<!-- * Una alternativa "moderna" es el método de bootstrap, introducida por Efron así casi 40 años (1979). Bootstrap es un método de remuestreo que es computacionalmente intensivo, y que es aplicable a una gran variedad de casos, incluyendo aquellos en los que los supuestos son más realistas.  -->
<!-- Visualmente: -->
<!-- https://seeing-theory.brown.edu/frequentist-inference/es.html -->
<!-- --- -->
<!-- # Bootstrap -->
<!-- ¿De dónde viene la expresión? -->
<!-- ![](https://img.huffingtonpost.com/asset/5b6b3f1f2000002d00349e9d.jpeg?cache=92vfjlaeaf&ops=scalefit_720_noupscale) -->
<!-- https://www.huffpost.com/entry/pull-yourself-up-by-your-bootstraps-nonsense_n_5b1ed024e4b0bbb7a0e037d4 -->
<!-- --- -->
<!-- ## Ejemplos de bootstrap -->
<!-- ### Ejemplo 1: La exactitud de una media muestral. -->
<!-- Tengo datos de sobrevivencia de 16 ratones luego de una cirugía de prueba: hay 9 ratones en el grupo control y 7 ratones en el grupo de tratamiento.  -->
<!-- | Group         | Survival time (in days)      | Mean  | -->
<!-- | ------------- |:----------------------------:| -----:| -->
<!-- | Treatment     | 94,197,16,38,99,141,23       | 86.86 | -->
<!-- | Control       | 52,104,146,10,51,30,40,27,46 | 56.22 | -->
<!-- ¿Podemos decir que el tratamiento es efectivo? -->
<!-- En estadística, resolvemos esa pregunta estimando $\bar{X}- \bar{Y} = 30.63$. El problema es cómo calcular la variabilidad, ¿podemos suponer lo mismo de siempre? -->
<!-- --- -->
<!-- ## Ejemplos de bootstrap -->
<!-- ### Ejemplo 1: La exactitud de una media muestral. -->
<!-- El problema se plantearía de la siguiente manera en teoría estadística: Suponga que una muestra $X_1, \dots, X_n$ es una muestra aleatoria con media $\mu$ y variancia $\sigma^2$. Entonces, el error estándar de la media muestral es:  -->
<!-- $$se(\bar{X})= \sqrt(var(\bar{X})) = \frac{\sigma}{\sqrt{n}}$$  -->
<!-- Esto sugiere que podemos estimar el error estándar con $\hat{se}(\bar{X})=\frac{s}{\sqrt{n}}$. Y aquí, tenemos dos opciones: la primera utilizar el teorema del límite central (teoría asintótica) o también podemos utilizar el estadístico: -->
<!-- $$T = \frac{\bar{X}- \bar{Y}}{\sqrt{\hat{se}(\bar{X})^2 + \hat{se}(\bar{Y})^2}}$$ -->
<!-- ¿Cuál es el problema? En el caso asintótico, necesitamos de una muestra grande, y en el segundo caso, la distribución de T NO es conocida (podríamos usar la aproximación de Satterthwaite, pero eso sería solo una aproximación). -->
<!-- --- -->
<!-- ## Ejemplos de bootstrap -->
<!-- ### Ejemplo 2: La exactitud de una mediana muestral. -->
<!-- Ahora suponga que queremos comparar las medianas de cada tratamiento, en lugar de las medias. De la tabla anterior podemos calcular: -->
<!-- $med(X) = 94, \quad med(Y)=46 \quad \text{y} \quad T'= med(X) - med(Y)= 48$ -->
<!-- ¿Cómo podemos cuantificar la exactitud de las medianas muestrales? -->
<!-- * Teoría Estadística para Medianas muestrales: no existen fórmulas para el error estándar de las medianas muestrales en el caso de muestras pequeñas.  -->
<!-- * Suponga que la distribución $P$ de $X_i$ es continua con densidad $p(x)$. Entonces, para muestras grandes, la mediana se distribuye aproximadamente como: -->
<!-- $$med(X) \xrightarrow{d} N(m_p, \frac{\sigma^2}{4np(m_p)})$$ -->
<!-- donde $m_p$ es la mediana de la distribución P. -->
<!-- --- -->
<!-- ## Ejemplos de bootstrap -->
<!-- ### Ejemplo 2: La exactitud de una mediana muestral. -->
<!-- ¿Cuál es el(los) problema(s)? -->
<!-- * ¿Son 7 y 9 suficientes observaciones para utilizar una aproximación asintótica? -->
<!-- * Podemos estimar de manera fiable la densidad de $p(m_p)$? -->
<!-- * ¿Cómo afecta la estimación (asintótica) del error estándar el ancho del intervalo de confianza basado en la aproximación normal? -->
<!-- ### Otros ejemplos para ver más adelante:  -->
<!-- * ¿cómo estimar los errores de las estimaciones puntuales hechas con el algoritmo EM o SEM?  -->
<!-- * ¿cómo contrastar hipótesis acerca de si una distribución tiene una o varias modas? -->
<!-- --- -->
<!-- # Principios de Bootstrap -->
<!-- * Si no existe información acerca de la distribución, en la muestra observada podemos encontrar información acerca de la distribución subyacente. Por lo tanto, re-muestrear la muestra es la mejor forma de acercarnos a lo que obtendríamos si se pudiera la oportunidad de re-muestrear de la distribución poblacional. -->
<!-- * Suponga que una muestra $X = (X_1, \dots, X_n)^T$ es utilizada para estimar un parámetro $\theta$. Sea $\hat{\theta}= s(X)$ un estadístico para estimar el parámetro $\theta$. Para hacer inferencia acerca de $\theta$, nos interesa la distribución muestral de $\hat{\theta}$, o ciertos aspectos acerca de esa distribución: la exactitud de nuestra estimación, el intervalo de confianza, etc. En muchas aplicaciones, la distribución muestral de $\hat{\theta}$ no se puede encontrar. -->
<!-- * Si conociéramos la distribución poblacional $P$, podríamos sacar muestras $X^{(b)}, b=1,\dots,B$ de P usando métodos de Monte Carlo para estimar la distribución muestral del estimado. Sin embargo, si $F$ es desconocido, entonces bootstrap sugiere que podemos aproximar ese muestreo re-muestreando nuestra muestra original. Así, podemos encontrar la distribución *empírica* del estimador. -->
<!-- https://seeing-theory.brown.edu/frequentist-inference/es.html -->
<!-- --- -->
<!-- <\!-- # Asignación del proyecto 2 -->
<!-- https://malfaro2.github.io/XS3310-I20/proyecto2  -->
<!-- --- -\-> -->
<!-- class: center, middle -->
<!-- # ¿Qué discutimos hoy? -->
<!-- Estimación por intervalos, método del pivote. Fórmulas para las estimaciones por intervalo más comunes (media, diferencias de medias, variancias, etc., para distribuciones normales),  -->
<!-- # ¿Qué nos falta para el II Parcial? -->
<!-- Bootstrap y contrastes de hipótesis. -->

</body>
</html>
