<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
	"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">

<head>
<title>XS3310-I20_13.html</title>
<meta http-equiv="Content-Type" content="application/xhtml+xml;charset=utf-8"/>
<link rel="stylesheet" type="text/css" media="all" href="https://cdn.jsdelivr.net/npm/github-markdown-css/github-markdown.min.css"  />
<link rel="stylesheet" type="text/css" media="all" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/styles/github.min.css"  /><meta name='viewport' content='width=device-width, initial-scale=1, shrink-to-fit=no'><style> body { box-sizing: border-box; max-width: 740px; width: 100%; margin: 40px auto; padding: 0 10px; } </style><script id='MathJax-script' async src='https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'></script><script src='https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/highlight.min.js'></script><script>document.addEventListener('DOMContentLoaded', () => { document.body.classList.add('markdown-body'); document.querySelectorAll('pre[lang] > code').forEach((code) => { code.classList.add(code.parentElement.lang); }); document.querySelectorAll('pre > code').forEach((code) => { hljs.highlightBlock(code); }); });</script>
</head>

<body>

<p><code>{r setup, include=FALSE} knitr::opts_chunk$set(echo = TRUE) library(tidyverse)</code></p>
<p>class: center, middle</p>
<h1 id="qué-hemos-visto-hasta-ahora">¿Qué hemos visto hasta ahora?</h1>
<p>Todo sobre estimadores puntuales + pivotes e intervalos de confianza. Bootstrap y una introducción a los contrastes de hipótesis.</p>
<h1 id="qué-vamos-a-discutir-hoy">¿Qué vamos a discutir hoy?</h1>
<p>Contrastes de hipótesis: función de potencia, tamaño del contraste, el valor p.</p>
<hr />
<h2 id="valor-p">Valor p</h2>
<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/9jW9G8MO4PQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</center>
<hr />
<h2 id="valor-p-1">Valor p</h2>
<p>El Valor p es una herramienta que se puede utilizar para contrastar hipótesis que tiene características que pueden solucionar algunos problemas con los contrastes anteriores. Por ejemplo, no todos los contrastes van a tener un tamaño de contraste exacto (como en los casos donde las variables aleatorias son discretas.) Por otro lado, ni el tamaño ni la potencia están directamente relacionados con los datos observados. El valor p corrige estos problemas. Para propósitos del curso definiremos el valor p como:</p>
<blockquote>
<p>Definición. <strong>Valor p:</strong> Sea <span class="math inline">\(T = T(X_1, X_2, \dots, X_n)\)</span> un estadístico y considere <span class="math inline">\(H_0: \theta = \theta_0\)</span> contra <span class="math inline">\(H1: \theta &lt; \theta_0\)</span> (o <span class="math inline">\(H1: \theta &gt; \theta_0\)</span>, <span class="math inline">\(H1: \theta \neq \theta_0\)</span>). Suponga que el contraste rechaza H0 si <span class="math inline">\(T \leq k\)</span> (o <span class="math inline">\(T &gt; k\)</span>, <span class="math inline">\(|T|&gt;k\)</span>). Sea <span class="math inline">\(t = T(x_1, x_2, \dots, x_n\)</span>) un valor observado de T. Entonces se define el valor p (denotado pval(t)) como: <span class="math display">\[pval(t) = P(T \leq t|\theta = \theta_0)\]</span><br />
<span class="math display">\[pval(t) = P(T &gt; t|\theta = \theta_0)\]</span> <span class="math display">\[pval(t) = 2 P(T &gt; t|\theta = \theta_0)\]</span></p>
</blockquote>
<hr />
<h2 id="valor-p-2">Valor p</h2>
<p>Nótese que de esta manera no hay ningún problema si la distribución de T es discreta o continua, pues la probabilidad puede ser calculada sin ningún problema. Formalmente, el valor p se conoce como la probabilidad, bajo la hipótesis nula, de observar nuestro estadístico de prueba o un valor más extremo. Esto significa que si el valor p es grande entonces nuestro estadístico de prueba es un valor muy común de T y se sitúa en el centro de la distribución, brindando así evidencia a favor de la hipótesis nula. Por otra parte, si el valor p es pequeño entonces el estadístico de prueba es un valor poco común de T, situándose en las colas de su distribución, y por lo tanto brindando evidencia en contra de <span class="math inline">\(H_0\)</span> y a favor de <span class="math inline">\(H_1\)</span>. Existe la posibilidad de que el valor de t haya sido un punto extremo de la distribución de T bajo <span class="math inline">\(H_0\)</span>, pero esto se considera algo como sumamente improbable.</p>
<p>Como altos valores p dan evidencia a favor de H0 y bajos valores dan evidencia en contra, sería posible idear un contraste de hipótesis que consista en rechazar H0 si (pval(t) ). Si la distribución de T es continua entonces el valor de () sería un tamaño de contraste exacto. En la práctica así es cómo se utiliza el valor p, comparándolo contra el nivel de significancia (tamaño del contraste) y decidiendo si se rechaza o no la hipótesis nula.</p>
<hr />
<h2 id="valor-p-3">Valor p</h2>
<!-- **Ejemplo:** Encuentre el valor p para la prueba anterior, suponiendo que $\bar{x} = 5,21$ y $n = 4$. -->
<!-- **Solución:** Recordemos que el contraste consistía en rechazar $H_0: \mu = 5$ a favor de $H_1:\mu > 5$ si $x > 5 + \frac{1,28}{\sqrt{n}}$. Por lo tanto el valor p consiste en encontrar la siguiente probabilidad: -->
<!-- $$\operatorname{pval}(5,21) = P(\bar{X} > 5,21|\mu = 5) = P(Z > \sqrt{4}(5,21 - 5)))$$ -->
<!-- $$= P(Z > 0,42) = 0,337$$ -->
<!-- Por lo tanto si comparamos este valor contra el tamaño de contraste que utilizamos anteriormente ($0.10$), decimos que no hay suficiente evidencia estadística para rechazar la hipótesis nula de que $\mu = 5$, ya que $\operatorname{pval}(5,21) = 0,337 > 0,10 = \alpha_0$. Esta conclusión es consistente con el -->
<!-- contraste que consiste en comparar $\bar{x}$ contra $5 + \frac{1,28}{\sqrt{n}}$. En este caso el valor crítico sería $5.64$, por lo que nuestro estadístico de prueba es menor y entonces no rechazamos la hipótesis nula. -->
<p><strong>Ejemplo</strong> Se rechaza <span class="math inline">\(H_0: \mu = \mu_0\)</span> si (|Z|&gt;z_{1-2})</p>
<p>Ahora si (= 0.05) y (z_{1-2} = 1.96), entonces para (Z = 1.97) y (Z = 2.78 ) y ( Z = 6.97) todos cumplen esa condición.</p>
<p>¿Entonces la pregunta es cuál es mejor?</p>
<p>Una forma de estimar esa “fuerza”, es partir del cuantil real de la distribución</p>
<p><span class="math display">\[\begin{align*}
\Phi(Z) &amp;&gt; 1-\dfrac{\alpha}2 \\
\alpha &amp;&gt; 2(1-\Phi(Z)) 
\end{align*}\]</span></p>
<ul>
<li>Si <span class="math inline">\(Z=1.97\)</span> entonces (=<code>r 2*(1-pnorm(1.97))</code>)</li>
<li>Si <span class="math inline">\(Z=2.78\)</span> entonces (=<code>r 2*(1-pnorm(2.78))</code>)</li>
<li>Si <span class="math inline">\(Z=6.97\)</span> entonces (=<code>r 2*(1-pnorm(6.97))</code>)</li>
</ul>
<p>En cada caso se estimó usando el comando <code>2*(1-pnorm(1.97))</code> por ejemplo.</p>
<hr />
<h2 id="valor-p-4">Valor p</h2>
<p>Existen algunas malas interpretaciones del valor p que no debemos cometer en la práctica. Por lo tanto concluyo esta discusión con dos advertencias:</p>
<ul>
<li><p>El valor p no es la probabilidad de que la hipótesis nula sea cierta. La hipótesis nula es un valor de () fijo y por lo tanto es cierta o no lo es; no existen probabilidades en este ámbito.</p></li>
<li><p>El valor p no es la probabilidad de cometer un Error Tipo I, dado los datos. El cálculo del valor p no tiene nada que ver con la decisión de aceptar o rechazar la hipótesis nula; es simplemente la probabilidad de una cola de la distribución muestral de T que se puede usar para cuantificar la evidencia de los datos a favor de H0. No obstante, sí se puede usar el valor p para tomar decisiones, pero entonces obviamente en esos caso no sería la probabilidad de Error Tipo I.</p></li>
<li><p>En algunos casos el valor p se conoce como el “tamaño del contraste observado” pues su cálculo es similar al del tamaño del contraste pero utilizando el estadístico de prueba en lugar del valor crítico. No obstante esta es una interpretación que no me gusta pues tiende a confundir la interpretación de un valor p con las interpretaciones erróneas mencionadas anteriormente.</p></li>
</ul>
<hr />
<figure>
<img src="figs/Fisher0.05.png" alt="Lo que Fisher dijo de p &lt; 0.05" /><figcaption aria-hidden="true">Lo que Fisher dijo de p &lt; 0.05</figcaption>
</figure>
<hr />
<h1 id="un-ejemplo-numérico">Un ejemplo numérico</h1>
<p>Los datos de la cantidad de lluvia para este experimento están acá. <code>{r 09-pruebas-hipotesis-1 } nubes &lt;- read.table(file = "./data/clouds.txt", sep = "\t", header = TRUE) head(nubes)</code></p>
<hr />
<p>Sin embargo usaremos los datos en escala logarítmica para facilitar el cálculo</p>
<p><code>{r 09-pruebas-hipotesis-2 } lognubes &lt;- log(nubes) head(lognubes)</code></p>
<hr />
<p>Observe que el comportamiento es distinto en ambos casos.</p>
<p>```{r 09-pruebas-hipotesis-3, echo=FALSE } df &lt;- as.data.frame(nubes) %&gt;% pivot_longer( cols = everything(), names_to = “tratamiento”, values_to = “lluvia” ) %&gt;% mutate(log_lluvia = log(lluvia)) ggplot(data = df) + geom_histogram(aes( x = lluvia, y = ..density.., fill = tratamiento ), color = “black”, bins = 10 ) + facet_wrap(. ~ tratamiento)</p>
<pre><code>
---

```{r, echo=FALSE}
ggplot(data = df) +
  geom_histogram(aes(
    x = log_lluvia,
    y = ..density..,
    fill = tratamiento
  ), color = &quot;black&quot;, bins = 10) +
  facet_wrap(. ~ tratamiento)
</code></pre>
<hr />
<p>En este caso supondremos que la variable <code>log_lluvia</code> se puede modelar como una <span class="math inline">\(N(\mu,\sigma^2)\)</span>, <span class="math inline">\(\mu,\sigma\)</span> desconocidos.</p>
<p>Preguntamos lo siguiente:</p>
<p>En este caso sería <span class="math inline">\(\theta = (\mu,\sigma^2)\)</span>, ¿Será cierto que para <span class="math inline">\(\theta\in\{(\mu,\sigma^2):\mu&gt;4\}\)</span>?</p>
<p>El valor de <span class="math inline">\(\mu&gt;4\)</span> nace a partir de una pregunta de investigación y se fórmula una <strong>hipótesis</strong> con respecto a los datos.</p>
<p>En este caso el valor donde decrece la curva es cercano a 0. Eso quiere decir que antes de ese valor, nos encontramos en la región de rechazo. Luego esa región se va haciendo cada vez más pequeña ( - ).</p>
<hr />
<p>Ojo lo que pasaría si por ejemplo cambiamos a <span class="math inline">\(\mu = 4\)</span>, asumiento que tenemos una población <span class="math inline">\(N(2,9)\)</span>.</p>
<p>```{r 09-pruebas-hipotesis-5, echo=FALSE } X &lt;- matrix(rnorm(1000 * 1000, mean = 2, sd = 3), ncol = 1000)</p>
<p>Xbar &lt;- apply(X, 2, mean)</p>
<p>mu0 &lt;- 4 T &lt;- abs(Xbar - mu0) c &lt;- seq(-0.25, 3, length.out = 1000) df &lt;- data.frame(c = numeric(), test = logical(), region = character()) for (k in 1:length(c)) { df &lt;- rbind( df, data.frame(c = c[k], test = mean(T &gt;= c[k]), region = “Omega_1”) ) } df &lt;- rbind(df, data.frame(c, test = 1 - df$test, region = “Omega_0”)) ggplot(df, aes(x = c, y = test, color = region)) + geom_line(size = 2) + ylab(“Promedio de veces donde T &gt;= c”) + theme_minimal()</p>
<pre><code>---

El valor donde comienza a crecer la curva se desvía a un valor cercano a 2. 

Para el caso del ejemplo de la lluvia definimos
que


$$H_0: \mu \leq 4 \text{ versus } H_1: \mu &gt; 4$$


En este caso podríamos decir que rechazamos \( H_0 \) si la media empírica
es &quot;más grande&quot; que 4 y no rechazamos \( H_0 \) si la media empírica es &quot;más
pequeña&quot; que 4.

El problema acá es que &quot;más grande&quot; y &quot;más pequeña&quot; no son términos precisos. 


---


Tenemos dos opciones 

Construya la región de critica de la forma 

$$\Omega_{0}=\left\{\boldsymbol{x}:\leq \bar{X}_{n}-\mu_{0} \leq
  c\right\}, \quad \text { y } \quad \Omega_{1}=\Omega_{0}^{C}$$

y observe cuál es la probabilidad que ocurra para cada tipo de \( c \).  El
problema con esta construcción es que requiere conocer todos los posibles
vectores de datos \( \mathbf{X} \) y construir los conjuntos \(\Omega_0 \) y \(\Omega_1
\). 

Una mejor opción es tener un estadístico sencillo que cumpla dos condiciones: 

1. Un estadístico sencillo de calcular posiblemente suficiente, minimal y
eficiente. 
2. Un estadístico con una distribución conocida. 


En ese caso \(\overline{X}_{n} \) funciona muy bien, porque tiene todas las
buenas propiedades de sufiencia, minimalidad y eficiencia, y además sabemos su
distribución según lo estudiando en capítulos pasados. Entonces 

\begin{equation*}
U = \frac{n ^{1/2} (\overline{X}_{n} - \mu_0)}{s} \sim t_{n-1}
\end{equation*}

Lo natural debería ser rechazar \( H_{0} \) si \( U \) es grande. 

---

```{r 09-pruebas-hipotesis-6,warning=FALSE }
colnames(lognubes)
Xbarra1 &lt;- mean(lognubes[, 1])
Xbarra2 &lt;- mean(lognubes[, 2])
sigma_prima1 &lt;- sd(lognubes[, 1])
sigma_prima2 &lt;- sd(lognubes[, 2])
n &lt;- dim(lognubes)[1]
(U1 &lt;- sqrt(n) * (Xbarra1 - 4) / sigma_prima1)
(U2 &lt;- sqrt(n) * (Xbarra2 - 4) / sigma_prima2)
</code></pre>
<hr />
<p><code>{r, echo=FALSE} ggplot(data = data.frame(x = (c(-1, 4))), mapping = aes(x)) +   stat_function(     fun = dt, args = list(df = n - 1),     mapping = aes(color = "Distribucioń t-student"), size = 2   ) +   geom_vline(mapping = aes(     xintercept = U1,     color = "Nubes no tratadas"   ), size = 2) +   geom_vline(mapping = aes(     xintercept = U2,     color = "Nubes tratadas"   ), size = 2) +   theme_minimal()</code></p>
<ul>
<li><p>Estadístico de prueba: <span class="math inline">\(T = |\bar X_n-\mu_0|\)</span>.</p></li>
<li><p>Región de rechazo: <span class="math inline">\(R = (c,\infty)\)</span>.</p></li>
</ul>
<p>Como <span class="math inline">\(X_1,\dots, X_n \sim N(\mu, \sigma^2)\)</span>, <span class="math inline">\(\mu\)</span> desconocido, <span class="math inline">\(\sigma^2\)</span> conocido entonces <span class="math inline">\(\bar X_n \sim N\left(\mu,\dfrac{\sigma^2}{n}\right)\)</span></p>
<ul>
<li>Función de potencia:</li>
</ul>
<p><span class="math display">\[\begin{align*}
Potencia(\theta) =  \mathbb P[T\in R|\mu] &amp; = \mathbb P [|\bar X_n -\mu_0|&gt;c|\mu] \\ &amp;= \mathbb P [\bar X_n &gt; \mu_0+c|\mu] + \mathbb P [\bar X_n &lt; \mu_0-c|\mu]\\
&amp; =  \mathbb P \bigg[\sqrt n \dfrac{(\bar X_n-\mu)}{\sigma}&gt; \dfrac{(\mu_0+c-\mu)}{\sigma}\sqrt n \bigg|\mu\bigg] +  \mathbb P \bigg[\sqrt n \dfrac{(\bar X_n-\mu)}{\sigma}&lt; \dfrac{(\mu_0-c-\mu)}{\sigma}\sqrt n \bigg|\mu\bigg] \\
&amp; = 1-\Phi\left(\sqrt n \dfrac{(\mu_0+c-\mu)}{\sigma} \right) + \Phi\left(\sqrt n \dfrac{(\mu_0-c-\mu)}{\sigma} \right) 
\end{align*}\]</span></p>
<p>```{r 09-pruebas-hipotesis-7 } mu0 &lt;- 4 c &lt;- 2 n &lt;- 100 sigma &lt;- 3 mu &lt;- seq(0, 8, length.out = 1000) funcion_de_poder &lt;- 1 - pnorm(sqrt(n) * (mu0 + c - mu) / sigma) + pnorm(sqrt(n) * (mu0 - c - mu) / sigma) df &lt;- data.frame(mu, funcion_de_poder, tipo = “Función de poder”) df &lt;- rbind(df, data.frame(mu, funcion_de_poder = 1 - df$funcion_de_poder, tipo = “1 - Función de poder” )) ggplot(df, aes(mu, funcion_de_poder, color = tipo)) + geom_line(size = 2) + theme_minimal() mu &lt;- seq(0, 8, length.out = 100) c &lt;- seq(0, 4, length.out = 100) mu_c &lt;- expand.grid(mu, c) funcion_de_poder_n_c &lt;- 1 - pnorm(sqrt(n) * (mu0 + mu_c[, 2] - mu_c[, 1]) / sigma) + pnorm(sqrt(n) * (mu0 - mu_c[, 2] - mu_c[, 1]) / sigma)</p>
<pre><code>

**Tipos de error**:

En este tipo de pruebas se puede cometer dos tipos de errores, 

* *Error Tipo I*: error de rechazar $H_0$ si $\theta \in \Omega_0$.

* *Error Tipo II*: error de no rechazar $H_0$ si $\theta\in\Omega_1$ en términos de la función de potencia.

En términos de la función de poder tenemos que 

- Si $\theta \in \Omega_0$: $Potencia(\theta|\delta)$ es el error tipo I. 
- Si $\theta \in \Omega_1$: $1-Potencia(\theta|\delta)$ es el error tipo II.

 El objetivo es hacer $Potencia(\theta|\delta)$ pequeño cuando $\theta\in\Omega_0$.
También se requiere que $Potencia(\theta|\delta)$ sea grande cuando $\theta
\in\Omega_1$. Una forma de alcanzar ese balance es seleccionar $\alpha_0 \in
(0,1)$ tal que

\[Potencia(\theta|\delta) \leq \alpha_0\;\forall \theta\in\Omega_0\quad(*)\]
y entre todas las pruebas que cumplan $(*)$ se selecciona aquella que maximice la potencia para $\theta \in \Omega_1$.

En nuestro ejemplo suponga que elegimos \(\alpha_{0} = 0.1\). La región roja
  indica donde estaría ubicado \(Potencia(\theta\vert \delta)\leq \alpha_{0} \). 
  
```{r 09-pruebas-hipotesis-8 }
ggplot() +
  geom_line(
    data = df,
    mapping = aes(x = mu, y = funcion_de_poder, color = tipo), size = 2
  ) +
  geom_rect(
    data = data.frame(xmin = 0, xmax = 8, ymin = 0, ymax = 0.10),
    mapping = aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax),
    alpha = 0.5, fill = &quot;red&quot;
  ) +
  geom_hline(yintercept = 0.05) +
  theme_minimal()</code></pre>
<hr />
<h1 id="valor-p-5">Valor p</h1>
<p>El estadístico de prueba para las nubes tratadas</p>
<pre class="{r}"><code>(n &lt;- length(lognubes$Seeded.Clouds))
(Xbarra &lt;- mean(lognubes$Seeded.Clouds))
(sigma &lt;- sd(lognubes$Seeded.Clouds))
 
(T &lt;- (Xbarra - 4)/(sigma/sqrt(n)))</code></pre>
<pre class="{r}"><code>2 * (1 - pt(T, df = n - 1))</code></pre>
<hr />
<h1 id="valor-p-6">Valor p</h1>
<p>El estadístico de prueba para las lognubes no tratadas</p>
<pre class="{r}"><code>(n &lt;- length(lognubes$Unseeded.Clouds))
(Xbarra &lt;- mean(lognubes$Unseeded.Clouds))
(sigma &lt;- sd(lognubes$Unseeded.Clouds))

(T &lt;- (Xbarra - 4) / (sigma / sqrt(n)))</code></pre>
<pre class="{r}"><code>2 * (1 - pt(T, df = n - 1))</code></pre>
<hr />
<h1 id="en-r">En R</h1>
<pre class="{r}"><code>t.test(lognubes$Seeded.Clouds, mu = 4)</code></pre>
<hr />
<h1 id="en-r-1">En R</h1>
<pre class="{r}"><code>t.test(lognubes$Unseeded.Clouds, mu = 4)</code></pre>
<hr />
<p>class: center, middle</p>
<h1 id="qué-discutimos-hoy">¿Qué discutimos hoy?</h1>
<p>Contrastes de hipótesis: función de potencia, tamaño del contraste, el valor p.</p>

</body>
</html>
